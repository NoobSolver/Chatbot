{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Conversations From Customer Service Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, re, itertools, collections, string, time\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from time import time\n",
    "import datetime\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "complaints_df_raw = pd.read_csv(\"consumer_complaints.csv\", \n",
    "                usecols=('Product','Consumer complaint narrative', 'Sub-issue'),\n",
    "                dtype={'consumer_complaint_narrative': object})\n",
    "# Only interested in data with consumer complaints\n",
    "complaints_df_raw=complaints_df_raw[complaints_df_raw['Consumer complaint narrative'].notnull()]\n",
    "complaints_df_raw=complaints_df_raw[complaints_df_raw['Product'].notnull()]\n",
    "\n",
    "# remove XXXX from narratives\n",
    "complaints_df_raw['Consumer complaint narrative'] =  complaints_df_raw['Consumer complaint narrative'].replace({'X':''}, regex=True)\n",
    "\n",
    "# always seed your random generators for reporducilibity \n",
    "complaints_df_raw = complaints_df_raw.sample(200000, replace=False, random_state=1)\n",
    "\n",
    "# basic sentence prep\n",
    "# set to lower\n",
    "complaints_df_raw['Consumer complaint narrative'] = complaints_df_raw['Consumer complaint narrative'].str.lower()\n",
    "# remove special characters\n",
    "complaints_df_raw['Consumer complaint narrative'] = complaints_df_raw['Consumer complaint narrative'].str.replace('\\W', ' ')\n",
    "\n",
    "# remove elements with no text\n",
    "complaints_df_raw= complaints_df_raw[complaints_df_raw['Consumer complaint narrative'] != '']\n",
    "\n",
    "# any dups\n",
    "complaints_df_raw = complaints_df_raw.drop_duplicates(subset=['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332635</th>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wells fargo   2015 took   16000 00  from my cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992324</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "      <td>computer base system pre approve me for a cred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902590</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>i have a dept on my credit report which is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618944</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Information is not mine</td>\n",
       "      <td>upon getting my credit report  i noted an addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834643</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Information belongs to someone else</td>\n",
       "      <td>i never consented to be a co signer  account d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Product  \\\n",
       "332635                            Bank account or service   \n",
       "992324  Credit reporting, credit repair services, or o...   \n",
       "902590                                    Debt collection   \n",
       "618944                                   Credit reporting   \n",
       "834643  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "                                                Sub-issue  \\\n",
       "332635                                                NaN   \n",
       "992324  Credit inquiries on your report that you don't...   \n",
       "902590                                  Debt is not yours   \n",
       "618944                            Information is not mine   \n",
       "834643                Information belongs to someone else   \n",
       "\n",
       "                             Consumer complaint narrative  \n",
       "332635  wells fargo   2015 took   16000 00  from my cr...  \n",
       "992324  computer base system pre approve me for a cred...  \n",
       "902590  i have a dept on my credit report which is not...  \n",
       "618944  upon getting my credit report  i noted an addr...  \n",
       "834643  i never consented to be a co signer  account d...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = complaints_df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194410, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity=complaints_df['Consumer complaint narrative'].str.split(' ').map(Counter)\n",
    "word_similarity_ratio = []\n",
    "complaints_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    194410.000000\n",
       "mean          2.114613\n",
       "std           1.131822\n",
       "min           1.000000\n",
       "25%           1.636364\n",
       "50%           1.990741\n",
       "75%           2.432749\n",
       "max         240.619048\n",
       "Name: narrative_similarity_ratio, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for wu in word_similarity:\n",
    "    word_similarity_ratio.append(np.sum([x[1] for x in wu.items()])/np.float(len(wu)))\n",
    "    \n",
    "complaints_df['narrative_similarity_ratio'] = word_similarity_ratio\n",
    "complaints_df['narrative_similarity_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57150, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thin out some entries that contain too much duplicated lines within\n",
    "complaints_df = complaints_df[complaints_df['narrative_similarity_ratio'] <= 1.7]\n",
    "complaints_df.reset_index(drop=True,inplace=True)\n",
    "complaints_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer base system pre approve me for a credit limit then decline my application',\n",
       " 'i have a dept on my credit report which is not mine  i have spoke with the company a while ago and its still being reported  i do n t know what else to do but file a complaint ',\n",
       " 'upon getting my credit report  i noted an address of     il on there with a possible loan store credit card and possibly more obtained attempted and possibly utilities use connection using my name  this address is was my ex husband and his new wife     and    they have tried this before in getting cell phones  i would like more information on what who they used my info for and what i can do about it please  these were noted on my transunion credit report and i am unable to get my   right away because it shows accounts i do not recognize on there ',\n",
       " 'i never consented to be a co signer  account does not belong to me  i am a victim of fraud ']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(complaints_df['Consumer complaint narrative'])[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Key Verbs And Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most common verbs and measure coverage \n",
    "import spacy\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load('en')\n",
    "\n",
    "# just load what we need to avoid taxing memory\n",
    "nlp = spacy.load('en', parser=False, entity=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create one big blob of text to process things a bit faster\n",
    "blob_complaints = ''.join(list(complaints_df['Consumer complaint narrative']))\n",
    "\n",
    "# Max text of length of 1000000\n",
    "n = 900000\n",
    "blog_chunks = [blob_complaints[i:i+n] for i in range(0, len(blob_complaints), n)]\n",
    "len(blog_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "just_verbs = []\n",
    "just_nouns = []\n",
    "counter_=len(blog_chunks)\n",
    "for sentence in blog_chunks:\n",
    "    counter_ -= 1\n",
    "    if (counter_ % 10 == 0): print(counter_)\n",
    "    print(counter_)\n",
    "    doc = nlp(sentence.decode('utf-8'))\n",
    "    temp_verb = []\n",
    "    temp_noun = []\n",
    "    for token in doc: \n",
    "        if (token.pos_ == u'VERB'): \n",
    "            temp_verb.append(token.text)\n",
    "        if (token.pos_ == u'NOUN'):\n",
    "            temp_noun.append(token.text)\n",
    "            \n",
    "\n",
    "    just_verbs.append(' '.join(temp_verb).encode('utf-8'))\n",
    "    just_nouns.append(' '.join(temp_noun).encode('utf-8'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['approve',\n",
       " 'decline',\n",
       " 'have',\n",
       " 'is',\n",
       " 'have',\n",
       " 'spoke',\n",
       " 'being',\n",
       " 'reported',\n",
       " 'do',\n",
       " 'know']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_verbs[0].split()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['computer',\n",
       " 'base',\n",
       " 'system',\n",
       " 'pre',\n",
       " 'credit',\n",
       " 'limit',\n",
       " 'applicationi',\n",
       " 'dept',\n",
       " 'credit',\n",
       " 'report']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_nouns[0].split()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count just_verbs: 20\n",
      "count just_nouns: 20\n"
     ]
    }
   ],
   "source": [
    "print('count just_verbs: %i' % len(just_verbs))\n",
    "print('count just_nouns: %i' % len(just_nouns))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle both objects so you don't have to re-run spacy \n",
    "import pickle\n",
    "pickle_file = \"verbs_nouns.p\"\n",
    "\n",
    "overwrite_old_pickle = True\n",
    "if overwrite_old_pickle:\n",
    "    with open(pickle_file, \"wb\") as f:\n",
    "        pickle.dump([just_verbs, just_nouns], f)\n",
    "    \n",
    "# read in saved pickle\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    backup_pos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Out Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "762105"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_verbs = backup_pos[0]\n",
    "len(all_verbs)\n",
    "\n",
    "# append all verbs together so we can run frequency counts\n",
    "verbs = []\n",
    "for verb_set in all_verbs:\n",
    "    verbs.append(verb_set.split())\n",
    "    #verbs = [verb for verb in verb_set[0].split()]\n",
    "\n",
    "len(verbs)\n",
    "verbs_master = [val for sublist in verbs for val in sublist]\n",
    "len(verbs_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>49226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>38867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>36476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has</td>\n",
       "      <td>16444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are</td>\n",
       "      <td>16046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>been</td>\n",
       "      <td>15056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>be</td>\n",
       "      <td>13915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>do</td>\n",
       "      <td>12502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>had</td>\n",
       "      <td>10626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>am</td>\n",
       "      <td>10541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>did</td>\n",
       "      <td>9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>received</td>\n",
       "      <td>8042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>would</td>\n",
       "      <td>7754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sent</td>\n",
       "      <td>7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>paid</td>\n",
       "      <td>7037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>were</td>\n",
       "      <td>6803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>get</td>\n",
       "      <td>6798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>can</td>\n",
       "      <td>6510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>called</td>\n",
       "      <td>6465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>will</td>\n",
       "      <td>6412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        verb  count\n",
       "0       have  49226\n",
       "1         is  38867\n",
       "2        was  36476\n",
       "3        has  16444\n",
       "4        are  16046\n",
       "5       been  15056\n",
       "6         be  13915\n",
       "7         do  12502\n",
       "8        had  10626\n",
       "9         am  10541\n",
       "10       did   9136\n",
       "11  received   8042\n",
       "12     would   7754\n",
       "13      sent   7241\n",
       "14      paid   7037\n",
       "15      were   6803\n",
       "16       get   6798\n",
       "17       can   6510\n",
       "18    called   6465\n",
       "19      will   6412"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is your upper and lower cut offs?\n",
    "from collections import Counter\n",
    "verbs_df = pd.DataFrame(Counter([verb for verb in verbs_master]).most_common(), columns = ['verb', 'count'])\n",
    "verbs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbs_df[verbs_df['count'] > 1000])\n",
    "verbs_df = verbs_df[verbs_df['count'] > 1000]\n",
    "len(verbs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting Out Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755822"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nouns = backup_pos[1]\n",
    "\n",
    "# append all verbs together so we can run frequency counts\n",
    "nouns = []\n",
    "for noun_set in all_nouns:\n",
    "    nouns.append(noun_set.split())\n",
    "\n",
    "nouns_master = [val for sublist in nouns for val in sublist]\n",
    "len(nouns_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit</td>\n",
       "      <td>40323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account</td>\n",
       "      <td>23173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>17342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>debt</td>\n",
       "      <td>16744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information</td>\n",
       "      <td>14105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          noun  count\n",
       "0       credit  40323\n",
       "1      account  23173\n",
       "2       report  17342\n",
       "3         debt  16744\n",
       "4  information  14105"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is your upper and lower cut offs?\n",
    "from collections import Counter\n",
    "nouns_df = pd.DataFrame(Counter([noun for noun in nouns_master]).most_common(), columns = ['noun', 'count'])\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns_df[nouns_df['count'] > 1000])\n",
    "nouns_df = nouns_df[nouns_df['count'] > 1000]\n",
    "len(nouns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize DataFrame With Official Verb & Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "40000\n",
      "30000\n",
      "20000\n",
      "10000\n",
      "0\n",
      "('length:', 57150)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57150, 278)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new data frame with key verbs and nouns as features\n",
    "key_words = list(nouns_df['noun']) + list(verbs_df['verb'])\n",
    "row_bools = []\n",
    "counter_ = len(complaints_df['Consumer complaint narrative'])\n",
    "for sentence in complaints_df['Consumer complaint narrative']:\n",
    "    counter_ -= 1\n",
    "    if (counter_ % 10000 == 0): print(counter_)\n",
    "    row_bool = []\n",
    "    words = sentence.split()\n",
    "    for kw in key_words:\n",
    "        row_bool.append(kw in words)\n",
    "    row_bools.append(row_bool)\n",
    "    \n",
    "print('length:', len(row_bools))\n",
    "row_bools = pd.DataFrame(row_bools, columns=key_words)    \n",
    "row_bools = row_bools.astype(int)\n",
    "row_bools.shape\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit</th>\n",
       "      <th>account</th>\n",
       "      <th>report</th>\n",
       "      <th>debt</th>\n",
       "      <th>information</th>\n",
       "      <th>company</th>\n",
       "      <th>loan</th>\n",
       "      <th>payment</th>\n",
       "      <th>bank</th>\n",
       "      <th>collection</th>\n",
       "      <th>...</th>\n",
       "      <th>show</th>\n",
       "      <th>tell</th>\n",
       "      <th>use</th>\n",
       "      <th>notified</th>\n",
       "      <th>receiving</th>\n",
       "      <th>feel</th>\n",
       "      <th>sending</th>\n",
       "      <th>shows</th>\n",
       "      <th>re</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit  account  report  debt  information  company  loan  payment  bank  \\\n",
       "0       1        0       0     0            0        0     0        0     0   \n",
       "1       1        0       1     0            0        1     0        0     0   \n",
       "2       1        0       1     0            1        0     1        0     0   \n",
       "3       0        1       0     0            0        0     0        0     0   \n",
       "4       0        0       0     0            0        0     0        0     1   \n",
       "\n",
       "   collection  ...   show  tell  use  notified  receiving  feel  sending  \\\n",
       "0           0  ...      0     0    0         0          0     0        0   \n",
       "1           0  ...      0     0    0         0          0     0        0   \n",
       "2           0  ...      0     0    1         0          0     0        0   \n",
       "3           0  ...      0     0    0         0          0     0        0   \n",
       "4           0  ...      0     0    0         0          0     1        0   \n",
       "\n",
       "   shows  re  work  \n",
       "0      0   0     0  \n",
       "1      0   0     0  \n",
       "2      1   0     0  \n",
       "3      0   0     0  \n",
       "4      0   0     0  \n",
       "\n",
       "[5 rows x 278 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_bools.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster of popular sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36    2978\n",
       "21    2224\n",
       "45    2160\n",
       "6     2010\n",
       "8     1846\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "TOTAL_CLUSTERS = 50\n",
    "\n",
    "# Number of clusters\n",
    "kmeans = KMeans(n_clusters=TOTAL_CLUSTERS)\n",
    "# Fitting the input data\n",
    "kmeans = kmeans.fit(row_bools)\n",
    "# Getting the cluster labels\n",
    "labels = kmeans.predict(row_bools)\n",
    "\n",
    "# add cluster back to data frame \n",
    "row_bools['cluster'] = labels\n",
    "\n",
    "row_bools['cluster'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36    2978\n",
       "21    2224\n",
       "45    2160\n",
       "6     2010\n",
       "8     1846\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_bools['cluster'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "data cluster shape: 850\n",
      "Cluster: 1\n",
      "data cluster shape: 605\n",
      "Cluster: 2\n",
      "data cluster shape: 99\n",
      "Cluster: 3\n",
      "data cluster shape: 858\n",
      "Cluster: 4\n",
      "data cluster shape: 775\n",
      "Cluster: 5\n",
      "data cluster shape: 1031\n",
      "Cluster: 6\n",
      "data cluster shape: 2010\n",
      "Cluster: 7\n",
      "data cluster shape: 1714\n",
      "Cluster: 8\n",
      "data cluster shape: 1846\n",
      "Cluster: 9\n",
      "data cluster shape: 1132\n",
      "Cluster: 10\n",
      "data cluster shape: 1122\n",
      "Cluster: 11\n",
      "data cluster shape: 775\n",
      "Cluster: 12\n",
      "data cluster shape: 1131\n",
      "Cluster: 13\n",
      "data cluster shape: 528\n",
      "Cluster: 14\n",
      "data cluster shape: 1034\n",
      "Cluster: 15\n",
      "data cluster shape: 1224\n",
      "Cluster: 16\n",
      "data cluster shape: 1641\n",
      "Cluster: 17\n",
      "data cluster shape: 1022\n",
      "Cluster: 18\n",
      "data cluster shape: 1089\n",
      "Cluster: 19\n",
      "data cluster shape: 712\n",
      "Cluster: 20\n",
      "data cluster shape: 671\n",
      "Cluster: 21\n",
      "data cluster shape: 2224\n",
      "Cluster: 22\n",
      "data cluster shape: 243\n",
      "Cluster: 23\n",
      "data cluster shape: 1232\n",
      "Cluster: 24\n",
      "data cluster shape: 1627\n",
      "Cluster: 25\n",
      "data cluster shape: 973\n",
      "Cluster: 26\n",
      "data cluster shape: 1145\n",
      "Cluster: 27\n",
      "data cluster shape: 1051\n",
      "Cluster: 28\n",
      "data cluster shape: 866\n",
      "Cluster: 29\n",
      "data cluster shape: 768\n",
      "Cluster: 30\n",
      "data cluster shape: 983\n",
      "Cluster: 31\n",
      "data cluster shape: 833\n",
      "Cluster: 32\n",
      "data cluster shape: 1115\n",
      "Cluster: 33\n",
      "data cluster shape: 1755\n",
      "Cluster: 34\n",
      "data cluster shape: 1320\n",
      "Cluster: 35\n",
      "data cluster shape: 941\n",
      "Cluster: 36\n",
      "data cluster shape: 2978\n",
      "Cluster: 37\n",
      "data cluster shape: 1246\n",
      "Cluster: 38\n",
      "data cluster shape: 1219\n",
      "Cluster: 39\n",
      "data cluster shape: 1643\n",
      "Cluster: 40\n",
      "data cluster shape: 86\n",
      "Cluster: 41\n",
      "data cluster shape: 989\n",
      "Cluster: 42\n",
      "data cluster shape: 1541\n",
      "Cluster: 43\n",
      "data cluster shape: 1489\n",
      "Cluster: 44\n",
      "data cluster shape: 1232\n",
      "Cluster: 45\n",
      "data cluster shape: 2160\n",
      "Cluster: 46\n",
      "data cluster shape: 981\n",
      "Cluster: 47\n",
      "data cluster shape: 162\n",
      "Cluster: 48\n",
      "data cluster shape: 1335\n",
      "Cluster: 49\n",
      "data cluster shape: 1144\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add cluster number back to orginal corpus\n",
    "complaints_df['Cluster'] = labels\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "unique_complaints_2grams = []\n",
    "unique_complaints_3grams = []\n",
    "unique_complaints_4grams = []\n",
    "unique_complaints_5grams = []\n",
    "unique_complaints_6grams = []\n",
    "# loop through each cluster\n",
    "for cluster_to_search in range(min(row_bools['cluster']), max(row_bools['cluster'])+1):\n",
    "    # cluster-level research\n",
    "    print('Cluster: %i' % cluster_to_search)\n",
    "    df_tmp = complaints_df[complaints_df['Cluster']==cluster_to_search].copy()\n",
    "    print('data cluster shape: %s' % len(df_tmp))\n",
    "    \n",
    "    bigrams = []\n",
    "    trigrams = []\n",
    "    fourgrams = []\n",
    "    fivegrams = []\n",
    "    sixgrams = []\n",
    "    \n",
    "    for index, row in df_tmp.iterrows(): \n",
    "        token = nltk.word_tokenize(row['Consumer complaint narrative'].decode('utf-8'))\n",
    "        bigrams.append([' '.join(pair) for pair in list(ngrams(token,2)) if len(set(pair))==2])\n",
    "        trigrams.append([' '.join(pair) for pair in list(ngrams(token,3)) if len(set(pair))==3])\n",
    "        fourgrams.append([' '.join(pair) for pair in list(ngrams(token,4)) if len(set(pair))==4])\n",
    "        fivegrams.append([' '.join(pair) for pair in list(ngrams(token,5)) if len(set(pair))==5])\n",
    "        sixgrams.append([' '.join(pair) for pair in list(ngrams(token,6)) if len(set(pair))==6])\n",
    "        \n",
    "    bigrams = [val for sublist in bigrams for val in sublist]\n",
    "    trigrams = [val for sublist in trigrams for val in sublist]\n",
    "    fourgrams = [val for sublist in fourgrams for val in sublist]\n",
    "    fivegrams = [val for sublist in fivegrams for val in sublist]\n",
    "    sixgrams = [val for sublist in sixgrams for val in sublist]\n",
    "    \n",
    "    # find top x most popular grams per size\n",
    "    # 2 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in bigrams]).most_common(50), columns=['bigrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_2grams.append(freqx)\n",
    "    # 3 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in trigrams]).most_common(50), columns=['trigrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_3grams.append(freqx)\n",
    "    # 4 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in fourgrams]).most_common(50), columns=['fourgrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_4grams.append(freqx)\n",
    "    # 5 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in fivegrams]).most_common(50), columns=['fivegrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_5grams.append(freqx)\n",
    "    # 6 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in sixgrams]).most_common(50), columns=['sixgrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_6grams.append(freqx)\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgrams</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>please help me i</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>would be greatly appreciated</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>have a foreclosure sale</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>a loan modification with</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>and now i am</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fourgrams  frequency  Cluster\n",
       "20              please help me i         14        0\n",
       "36  would be greatly appreciated         10        0\n",
       "38       have a foreclosure sale         10        0\n",
       "42      a loan modification with          9        0\n",
       "46                  and now i am          9        0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df = pd.concat(unique_complaints_4grams)\n",
    "    # freqx = pd.DataFrame(Counter([noun for noun in fourgrams]).most_common(50), columns=['fourgrams','frequency'])\n",
    "    df = df.drop_duplicates(subset=['fourgrams'], keep=False)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sixgrams</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>protocols in handling consumer information they</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>injured parties they are responsible for</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>by signing injured parties they are</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>signing injured parties they are responsible</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>risk of identity theft fraud due</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>are further attempting to capitalize on</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>situation by signing injured parties they</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>put myself and millions of others</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>equifaxsecurity2017 com they have put myself</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>in handling consumer information they are</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>consumer information they are further attempting</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>hidden terms of service that waive</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>com they have put myself and</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>handling consumer information they are further</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>have put myself and millions of</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>parties they are responsible for up</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>information they are further attempting to</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>their right to sue the company</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>waive their right to sue the</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>of service that waive their right</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>terms of service that waive their</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>identity theft fraud due to negligent</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>they have put myself and millions</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>fraud due to negligent security protocols</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>periods of their id protection services</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>of identity theft fraud due to</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>at risk of identity theft fraud</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>equifax mishandled my personal information inc...</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>others at risk of identity theft</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>personal information including name social sec...</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>well as ssn or dob in</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>must include name and address as</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>it to appear in your credit</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bureau has not updated the information</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>new law effective 2017 any public</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bankruptcy listed does not include this</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>incorrect information on my credit report</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be deleted from my credit report</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and should be deleted from my</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>information and should be deleted from</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>should be deleted from my credit</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public record data must include name</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>any public record data must include</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in order for it to appear</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this information and should be deleted</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017 any public record data must</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>credit bureau has not updated the</td>\n",
       "      <td>41</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>include this information and should be</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>listed does not include this information</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>under the new law effective 2017</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>law effective 2017 any public record</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>does not include this information and</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>effective 2017 any public record data</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>information and per the new law</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>not include this information and should</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the credit bureau has not updated</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>not updated the information and per</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>file the credit bureau has not</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the new law effective 2017 any</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>information on my credit report i</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sixgrams  frequency  Cluster\n",
       "28    protocols in handling consumer information they         53        1\n",
       "36           injured parties they are responsible for         52        1\n",
       "35                by signing injured parties they are         52        1\n",
       "34       signing injured parties they are responsible         52        1\n",
       "33                   risk of identity theft fraud due         52        1\n",
       "29            are further attempting to capitalize on         53        1\n",
       "31          situation by signing injured parties they         52        1\n",
       "30                  put myself and millions of others         52        1\n",
       "37       equifaxsecurity2017 com they have put myself         51        1\n",
       "32          in handling consumer information they are         52        1\n",
       "38   consumer information they are further attempting         51        1\n",
       "48                 hidden terms of service that waive         37        1\n",
       "40                       com they have put myself and         51        1\n",
       "41     handling consumer information they are further         51        1\n",
       "42                    have put myself and millions of         51        1\n",
       "43                parties they are responsible for up         51        1\n",
       "44         information they are further attempting to         51        1\n",
       "45                     their right to sue the company         38        1\n",
       "46                       waive their right to sue the         37        1\n",
       "47                  of service that waive their right         37        1\n",
       "49                  terms of service that waive their         37        1\n",
       "27              identity theft fraud due to negligent         53        1\n",
       "39                  they have put myself and millions         51        1\n",
       "26          fraud due to negligent security protocols         53        1\n",
       "16            periods of their id protection services         54        1\n",
       "24                     of identity theft fraud due to         53        1\n",
       "25                    at risk of identity theft fraud         53        1\n",
       "1   equifax mishandled my personal information inc...         57        1\n",
       "2                    others at risk of identity theft         57        1\n",
       "3   personal information including name social sec...         57        1\n",
       "..                                                ...        ...      ...\n",
       "45                              well as ssn or dob in         23       49\n",
       "25                   must include name and address as         40       49\n",
       "36                        it to appear in your credit         36       49\n",
       "24             bureau has not updated the information         41       49\n",
       "12                  new law effective 2017 any public         48       49\n",
       "22            bankruptcy listed does not include this         42       49\n",
       "47          incorrect information on my credit report         14       49\n",
       "0                    be deleted from my credit report         54       49\n",
       "1                       and should be deleted from my         53       49\n",
       "2              information and should be deleted from         52       49\n",
       "3                    should be deleted from my credit         52       49\n",
       "4                public record data must include name         52       49\n",
       "5                 any public record data must include         52       49\n",
       "6                           in order for it to appear         52       49\n",
       "7              this information and should be deleted         51       49\n",
       "8                    2017 any public record data must         50       49\n",
       "23                  credit bureau has not updated the         41       49\n",
       "9              include this information and should be         50       49\n",
       "11           listed does not include this information         48       49\n",
       "13                   under the new law effective 2017         48       49\n",
       "14               law effective 2017 any public record         47       49\n",
       "15              does not include this information and         47       49\n",
       "16              effective 2017 any public record data         46       49\n",
       "17                    information and per the new law         46       49\n",
       "18            not include this information and should         46       49\n",
       "19                  the credit bureau has not updated         44       49\n",
       "20                not updated the information and per         43       49\n",
       "21                     file the credit bureau has not         42       49\n",
       "10                     the new law effective 2017 any         48       49\n",
       "49                  information on my credit report i         13       49\n",
       "\n",
       "[837 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top x most popular grams per size\n",
    "see_grams = 6\n",
    "\n",
    "\n",
    "if see_grams==2:\n",
    "    df = pd.concat(unique_complaints_2grams)\n",
    "    df = df.drop_duplicates(subset=['bigrams'], keep=False)\n",
    "elif see_grams==3:\n",
    "    df = pd.concat(unique_complaints_3grams)\n",
    "    df = df.drop_duplicates(subset=['trigrams'], keep=False)\n",
    "elif see_grams==4:\n",
    "    df = pd.concat(unique_complaints_4grams)\n",
    "    df = df.drop_duplicates(subset=['fourgrams'], keep=False)\n",
    "elif see_grams==5:\n",
    "    df = pd.concat(unique_complaints_5grams)\n",
    "    df = df.drop_duplicates(subset=['fivegrams'], keep=False)\n",
    "elif see_grams==6:\n",
    "    df = pd.concat(unique_complaints_6grams)\n",
    "    df = df.drop_duplicates(subset=['sixgrams'], keep=False)\n",
    " \n",
    "df = df.sort_values('Cluster')\n",
    "df[df['frequency'] > 10]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tie It Back To Complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stellar recovery inc is attempting to collect a debt from me that i do n t owe them  i never established a contract with this company and they have reported negative items onto my  and  credit reports which is in violation of the fcra \n",
      "------\n",
      "i received a message from global credit and collection company who said it was attempting to collect a debt i owe  i called the number back who said it was a non working number for   this same company left a message on  other phone numbers that have never been associated with any account i have  it was disclosed on answering machines voicemail that they were attempting to collect a debt from me \n",
      "------\n",
      "trident asset management is attempting to collect a debt from me that i do n t owe them  i never established a contract with this company and they have reported negative items onto my  and  credit reports which is in violation of the fcra \n",
      "------\n",
      "this company is attempting to collect a debt from me and has reported this debt to the credit bureaus  the problem is this company has yet to provide verification of this debt  i have no idea who or what this debt is for and i have no contract with this agency \n",
      "------\n",
      "wakefield and associates of   colorado  has been attempting to collect a debt from me for one year  i have never received proof of the debt in writing they have called me multiple times during the day and evening  they have argued with me and have said they do not need to send paper proof of debts  the collection reported on my credit report does not match the amount they are seeking \n",
      "------\n",
      "rash curtis and associates is attempting to collect a debt from me that i have no awareness  via threatening to damage my credit \n",
      "------\n",
      " is attempting to collect a debt from me that i never establish a contract with this company nor do i owe any money to this company they are violating the fcra and placed negative reporting on both my  and  reports for amounts of  and   this debt is not collectable  these student loans were consolidated and i was never late \n",
      "------\n",
      "united collection bureau   robo calls    my home phone number daily attempting to collect a debt from some one else whose former phone number i was likely assigned after a recent move  i have called them back several times and have left messages for them to stop these calls as i am a new person with the debtor  s former number  i even spoke to a gentleman there once and explained to him that the number they have on file is no longer for the person which they are still attempting to reach  their calls have continued despite my threatening them with legal action \n",
      "------\n",
      "accouny discovery systems disclosed information about my debt to a third party without my consent  today after requesting them not to contact me at work or any other person who is not me trying to get a hold of me  they dishonored my request and contacted my mother at her job  instead of keeping my information discreet  they shared that they were attempting to collect a debt from me after my mother asked who was calling  is n t this supposed to be against the law  the fact that i am in debt should not be shared with anybody without my consent  i am getting tired of them harassing me and calling my employer and family members several times a day  i feel helpless \n",
      "------\n",
      "i continually receive calls attempting to collect a debt from my husband  s ex wife  i have repeatedly told them that they are contacting the wrong person  and they still call  i am unsure how my number got associated with her because i have had this number for twelve years  and i  ve only been married for four \n",
      "------\n",
      "the collection agency ic systems is attempting to collect a debt from me on behalf of  for unreturned cable equipment  firstly   has confirmed that i did return the equipment and owe them nothing  additionally   has told me that ic system is no longer an authorized collecter for   and is in fact harassing  customers \n",
      "------\n",
      "collection services of athens is attempting to collect a debt from me and i never established a contract with this company  furthermore collection services of athens is currently reporting negative information onto my  credit report indicating that i owe  amount of  and a additional amount for  dollars \n",
      "------\n",
      "maury cobb  attorney at law  located in   al keeps sending me robotic calls from  asking me to call   daily robotic calls to my cell phone attempting to collect a debt from someone who is unknown to me  i have contacted the caller twice to notify of the problem  but they have not changed tactics or otherwise changed their calling pattern  by nature of their systematic inability to source or acknowledge the problem i am effectively being harassed and am seeking relief \n",
      "------\n",
      "this company is attempting to collect a debt from me that i do n t owe them  i never established a contract with this company and they have reported negative items onto my  and  credit reports which is in violation of the fcra \n",
      "------\n",
      "national credit system is attempting to collect a debt from me for  dollars and i never established a contract with this company furthermore this company has reported negative items on to my credit report and is violating the fcra standard \n",
      "------\n",
      "i had forster garbus  llp contact me at my place of employment  which my employer does not allow  from phone number   they told me they are attempting to collect a debt from   a company i have never heard of  this debt they claim i have never been contacted about in the past  it does not show up on my credit report  and i have never heard of it  it is fraudulent and so was the harassing phone call \n",
      "------\n",
      "atg credit llc  is attempting to collect a debt from me that i never established a contract with this company at all  purchasing a debt and obtaining documentation or bills is not legal contract that binds to owe you any money at all  furthermore  atg credit llc is in complete violations of fcra by placing negative tradeline on to my credit reports which is complete slander to my name\n",
      "------\n",
      "i am dealing with the collection agency synergetic communication   inc  i am questioning how legitimate this company is for several reasons  they do not show up as the creditor on my credit report  and they are unlawfully attempting to collect a debt from me by violating several fdcpa laws  they have contacted me before  my time zone and have also called me several times within one hour  they have also never sent me a debt validation letter to make me aware they are the collection agency assigned and to advise me of my rights to dispute the validity of the debt \n",
      "------\n",
      "forster   garbus is attempting to collect a debt from me on a   credit card account that is from seven years ago  the debt is no longer listed on all three of my credit card reports the debt is listed as being for the amount of   970 00  \n",
      "------\n",
      "first financial mgmt is  attempting to collect a debt from me that i do n t owe  i never established a contract with this agency at all  obtainning documentation as a debt collection agency or third party vendor is not a contract or it does not legally bind me to pay this company any money  furthermore this agency is in complete violation of the fcra law by placing a negative tradeline on to my credit reports\n",
      "------\n",
      "i received a message from  company who said it was attempting to collect a debt i owe  i called the number back who said it was a non working number for chase  this same company left a message on  other phone numbers that have never been associated with any account i have  it was disclosed on answering machines voicemail that they were attempting to collect a debt from me \n",
      "------\n",
      "   is attempting to collect a debt from  that was discharged thru bankrutpcy  plus on top of that i never received any information about this debt before it hit my report  i would of told them it was no longer owed  thirdlly the original debt was in my mother  s name   \n",
      "------\n",
      "i have a collection company attempting to collect a debt from me that was the result of identity theft  i never had  as a phone company and yet this company has been relentless in trying to collect a debt thats not mine  somebody falsified my information and the original company sold the debt to a collection company instead of removing it since it was the result of fraud \n",
      "------\n",
      "ras lavrar is attempting to collect a debt from me that i have no recollection of  ras lavrar has stepped outside the boundaries fdpa  i have received a lot of harassment calls and even a representative came to my home or residences with harassments that are in violation of the fdpa  i never established a contract with this company and i don t owe the alleged debt i will be reporting this practice to the state attorney general office of ga and the ftc about this matter \n",
      "------\n",
      "cac financial corp is attempting to collect a debt from me that i do n t owe them  i never established a contract with this company and they have reported negative items onto my  and  credit reports which is in violation of the fcra \n",
      "------\n",
      "i have received a   2015 letter and various phone calls from central credit services  llc attempting to collect a debt from  in   these are most likely about a  services accrued in a bundled service  i have statements from  showing that the statements are paid in full  i previously filed a complaint with the ftc regarding this manner and i thought it was taken care of  now i am receiving bills at my new location in  \n",
      "------\n",
      "the collection agency that is attempting to collect a debt from me is not licensed to operate in my state  thus  i am disputing this collection  i have included the list of all active licenses for collection agencies from my state  s government website \n",
      "------\n",
      "a company called amerassist has called my mother in law  my father in law and a very distant cousin of mine  who i do not even have the contact information for myself  and has shared with them that they are attempting to collect a debt from me asking for information  they have called them on private home numbers and cell phone numbers  even after they ask to stop being contacted  i am unaware of any debt owed  and they are harassing people that i do not even speak with about alleged financial issues \n",
      "------\n",
      "diversified has called my office on multiple occasions from different numbers attempting to collect a debt from someone not associated with this office or myself      we  ve asked them to stop calling but they continue and i feel as if they are violating the fdcpa    can you please assist \n",
      "------\n",
      "i have received mutilate calls from them attempting to collect a debt from a medical visit i never had  if i had visited  my health insurname would have covered the visit and it would n t have cost me   260 00  like they are claiming \n",
      "------\n",
      "i am writing this complaint in regards to fco an debt collection company attempting to collect a debt from me  i have no proof or knowledge that i owe this debt  i moved out of  house in  of   2013 and paid any remaining balance i owed  i believe this debt is unjust and inaccurate \n",
      "------\n",
      "  credit collections    at  continues to call my numbers multiple times per week after i have written  submitted online requests and verbally informed them that the person they are attempting to collect a debt from  my ex     moved out in 2010  i have informed them he can not be reached at my numbers      multiple times but they continue to call repeatedly  i e  last tuesday they called 5 times between  and   then called twice on friday afternoon while i was trying to work  i have zero responsibility for my ex  s debts and am tired of this company harassing me even after i gave them his new number \n",
      "------\n",
      "pinnacle credit service is attempting to collect a debt from me of  and  and i never establish a contract with this company  and they are reporting negative items on both my  and  credit reports \n",
      "------\n",
      "enhanced recovery corp is attempting to collect a debt from me and i never established a contract with this company  furthermore erc is currently reporting negative information onto my  credit report \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# tie it back to look into a couple of actual complaints\n",
    "keywords = \"attempting to collect a debt from\"\n",
    " \n",
    "for index, row in complaints_df.iterrows():\n",
    "    txt = row['Consumer complaint narrative'] \n",
    "    if (keywords in txt):\n",
    "        print(txt)\n",
    "        print('------')\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
